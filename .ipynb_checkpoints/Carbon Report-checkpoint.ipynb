{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e751c49c",
   "metadata": {},
   "source": [
    "# Voluntary Carbon Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e5ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9707333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b15566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.ioff();\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://Attunga01:875mSzNM@attunga-instance-1.c6crotlobtrk.us-east-2.rds.amazonaws.com/postgres')\n",
    "\n",
    "sip_products = ['GEO','NGEO','CGEO-TR','CGEO','GEO']\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "#import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a1ec776",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from \\\"Verra_Issuance\\\"'\n",
    "iss = pd.read_sql(query, engine)\n",
    "iss = iss.drop_duplicates()\n",
    "iss['From Vintage'] = pd.to_datetime(iss['From Vintage'], format='%d/%m/%Y').dt.date\n",
    "iss['To Vintage'] = pd.to_datetime(iss['To Vintage'], format='%d/%m/%Y').dt.date      \n",
    "iss['Vintage'] = [i.year for i in iss['To Vintage']]  \n",
    "\n",
    "query = 'select * from \\\"Verra_Retirement\\\"'\n",
    "ret = pd.read_sql(query, engine)\n",
    "ret = ret.drop_duplicates()\n",
    "ret['Date of Retirement'] = pd.to_datetime(ret['Date of Retirement'], format='%Y-%m-%d').dt.date\n",
    "ret['From Vintage'] = pd.to_datetime(ret['From Vintage'], format='%Y-%m-%d').dt.date\n",
    "ret['To Vintage'] = pd.to_datetime(ret['To Vintage'], format='%Y-%m-%d').dt.date      \n",
    "ret['Vintage'] = [i.year for i in ret['To Vintage']] \n",
    "\n",
    "query = 'select * from \\\"VCS_Projects\\\"'\n",
    "proj = pd.read_sql(query, engine)\n",
    "proj = proj.drop_duplicates()\n",
    "proj['Crediting Period Start Date'] = pd.to_datetime(proj['Crediting Period Start Date'], format='%Y-%m-%d').dt.date\n",
    "proj['Crediting Period End Date'] = pd.to_datetime(proj['Crediting Period End Date'], format='%Y-%m-%d').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab0cc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_methods(issuance, retirement, projects):\n",
    "    # COOKSTOVES #\n",
    "    cookstrings = ['Stove','stove','Cooking','cooking','Cook','cook', 'STOVE','COOK', 'stew']\n",
    "    df_stove = issuance[issuance['Project Name'].str.contains('Stove')]\n",
    "    for c in cookstrings[1:]:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(c)]\n",
    "        df_stove = pd.concat([df_stove, df_sub])\n",
    "    df_stove = df_stove.drop_duplicates()\n",
    "    df_stove['Method'] = 'cookstoves'\n",
    "\n",
    "    # SOLAR #\n",
    "    solarstrings = ['Solar','solar','Photo','photo','PV', 'SOLAR', 'Pv']\n",
    "    df_solar = issuance[issuance['Project Name'].str.contains('Solar')]\n",
    "    for s in solarstrings[1:]:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(s)]\n",
    "        df_solar = pd.concat([df_solar, df_sub])\n",
    "    df_solar = df_solar.drop_duplicates()\n",
    "    df_solar['Method'] = 'solar'\n",
    "\n",
    "    # HYDRO #\n",
    "    strings = ['Hydro','hydro','River','river','HEPP', 'HYDRO', 'Foz do', 'Pizarras', 'Fundao', 'Hyrdro', 'Low Dam']\n",
    "    df_hydro = issuance[issuance['Project Name'].str.contains('Hydro')]\n",
    "    for s in strings[1:]:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(s)]\n",
    "        df_hydro = pd.concat([df_hydro, df_sub])\n",
    "    df_hydro = df_hydro.drop_duplicates()\n",
    "    df_hydro['Method'] = 'hydro'\n",
    "\n",
    "    # WIND #\n",
    "    strings = ['Wind','wind', 'WIND']\n",
    "    df_wind = issuance[issuance['Project Name'].str.contains('Wind')]\n",
    "    for s in strings[1:]:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(s)]\n",
    "        df_wind = pd.concat([df_wind, df_sub])\n",
    "    df_wind = df_wind.drop_duplicates()\n",
    "    df_wind['Method'] = 'wind'\n",
    "\n",
    "    # LANDFILL GAS / WASTE / Fugitive Emissions / CCS #\n",
    "    strings = ['Fill','fill', 'Waste','waste','CMM','CCS','capture','Capture', 'Biogas','biogas', 'LFG', 'Methane','methane','METHANE','Gas','gas', 'Biomass','biomass', 'compost', 'LNG', 'LANDFILL', 'Compost', 'Composting']\n",
    "    df_lfg = issuance[issuance['Project Type'].str.contains('Fugitive')]\n",
    "    for s in strings:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(s)]\n",
    "        df_lfg = pd.concat([df_lfg, df_sub])\n",
    "    df_lfg = df_lfg[~df_lfg['Project Type'].str.contains('Livestock')]\n",
    "    df_lfg = df_lfg[~df_lfg['Project Type'].str.contains('Forest')]\n",
    "    df_lfg = df_lfg.drop_duplicates()\n",
    "    df_lfg['Method'] = 'lfg_ccs_gas_biomass'\n",
    "\n",
    "    # GEOTHERMAL / BIOMASS #\n",
    "    strings = ['Geothermal','geothermal', 'Thermal','thermal']\n",
    "    df_geothermal = issuance[issuance['Project Name'].str.contains('Geothermal')]\n",
    "    for s in strings[1:]:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(s)]\n",
    "        df_geothermal = pd.concat([df_geothermal, df_sub])\n",
    "    df_geothermal = df_geothermal.drop_duplicates()\n",
    "    df_geothermal['Method'] = 'geothermal'\n",
    "\n",
    "    # LIVESTOCK / METHANE #\n",
    "    strings = ['Methane','methane','Dairy','dairy']\n",
    "    df_livestock = issuance[issuance['Project Name'].str.contains('Methane')]\n",
    "    for s in strings[1:]:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(s)]\n",
    "        df_livestock = pd.concat([df_livestock, df_sub])\n",
    "    df_livestock = df_livestock[df_livestock['Project Type'].str.contains('Livestock')]    \n",
    "    df_livestock = df_livestock.drop_duplicates()\n",
    "    df_livestock['Method'] = 'livestock_methane'\n",
    "\n",
    "    # FUEL SWITCHING #\n",
    "    strings = ['Switching','SWITCHING','switching', 'Husk', 'husk', 'Smelter', 'smelter', 'Switch']\n",
    "    df_switching = issuance[issuance['Project Name'].str.contains('Switching')]\n",
    "    for s in strings[1:]:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(s)]\n",
    "        df_switching = pd.concat([df_switching, df_sub])  \n",
    "    df_switching = df_switching.drop_duplicates()\n",
    "    df_switching['Method'] = 'fuel_switching'\n",
    "\n",
    "    ## AFFORESTATION ##\n",
    "    strings = ['Afforestation','afforestation','Plantation','plantation']\n",
    "    arr_projects = projects[projects['AFOLU Activities']=='ARR']\n",
    "    arr_projects = list(arr_projects['Project ID'].unique())\n",
    "\n",
    "    df_arr = issuance[issuance['Project Name'].str.contains('Afforestation')]\n",
    "    for s in strings[1:]:\n",
    "        df_sub = issuance[issuance['Project Name'].str.contains(s)]\n",
    "        df_arr = pd.concat([df_arr, df_sub])\n",
    "    x = issuance[issuance['Project ID'].isin(arr_projects)]\n",
    "    df_arr = pd.concat([df_arr, x])\n",
    "    df_arr = df_arr.drop_duplicates()\n",
    "    df_arr['Method'] = 'arr'\n",
    "\n",
    "    ## AVOIDED DEFORESTATION ##\n",
    "    df_avoided = issuance[issuance['Project Type'].str.contains('Forest')]\n",
    "    affo_projects = list(df_arr['Project ID'].unique())\n",
    "    df_avoided = df_avoided[~df_avoided['Project ID'].isin(affo_projects)]\n",
    "    df_avoided['Method'] = 'forestry_avoided'\n",
    "    df_avoided = df_avoided.drop_duplicates()\n",
    "\n",
    "    # Chemical #\n",
    "    df_chemical = issuance[issuance['Project Type'].str.contains('Chemical')]\n",
    "    df_chemical['Method'] = 'chemicals'\n",
    "    df_chemical = df_chemical.drop_duplicates()\n",
    "\n",
    "    # Plastic #\n",
    "    df_plastic = issuance[issuance['Project Type'].str.contains('Plastic')]\n",
    "    df_plastic['Method'] = 'plastics'\n",
    "    df_plastic = df_plastic.drop_duplicates()\n",
    "\n",
    "    # Transport #\n",
    "    df_transport = issuance[issuance['Project Type'].str.contains('Transport')]\n",
    "    df_transport['Method'] = 'transport'\n",
    "    df_transport = df_transport.drop_duplicates()\n",
    "\n",
    "    # BLUE CARBON #\n",
    "    sub1 = issuance[issuance['Project Name'].str.contains('BLUE')]\n",
    "    sub2 = issuance[issuance['Project Name'].str.contains('Blue')]\n",
    "    df_blue = pd.concat([sub1, sub2])\n",
    "    df_blue['Method'] = 'Blue Carbon'\n",
    "    df_blue = df_blue.drop_duplicates()\n",
    "\n",
    "\n",
    "    ## MERGE THEM ALL TOGETHER ##\n",
    "    df_issuance_merged = pd.concat([df_blue, df_stove, df_solar, df_hydro, df_wind, df_lfg, df_livestock, df_arr, df_avoided, df_chemical, df_plastic, df_transport, df_geothermal, df_switching])\n",
    "\n",
    "    # Other non-forestry # IDENTIFY THE MISSING PROJECTS\n",
    "    stripped_projects = list(df_issuance_merged['Project ID'].unique())\n",
    "    missing_projects = issuance[~issuance['Project ID'].isin(stripped_projects)] # find the projects that aren't yet accounted for\n",
    "    missing_projects['Method'] = 'other_non_forestry'\n",
    "\n",
    "    df_issuance_merged = pd.concat([df_issuance_merged, missing_projects])\n",
    "    df_issuance_merged = df_issuance_merged.drop_duplicates(subset=list(df_issuance_merged)[:-1])\n",
    "    df_issuance_merged = df_issuance_merged.sort_values(by=['Issuance Date','Project ID','To Vintage'], ascending=[False, True, True])\n",
    "    #df_issuance = df_issuance_merged.copy()\n",
    "    issuance = df_issuance_merged.copy()\n",
    "\n",
    "    ## UPDATE THE RETIREMENT DATA TO INCLUDE METHODS ##\n",
    "    #sub_df = issuance[['Project ID','Method']]\n",
    "    sub_df = issuance[['Project ID','Method']]\n",
    "    df_retirement = retirement.merge(sub_df, on='Project ID')\n",
    "    df_retirement = df_retirement.drop_duplicates().reset_index(drop=True)\n",
    "    #df_retirement = df_retirement.copy()\n",
    "    retirement = df_retirement.copy()\n",
    "\n",
    "    ## UPDATE THE PROJECTS DATA TO INCLUDE METHODS ##\n",
    "    #sub_df = issuance[['Project ID','Method']]\n",
    "    sub_df = issuance[['Project ID','Method']]\n",
    "    df_project = projects.merge(sub_df, on='Project ID')\n",
    "    df_project = df_project.drop_duplicates().reset_index(drop=True)\n",
    "    #df_projects = df_project.copy()\n",
    "    projects = df_project.copy()\n",
    "    \n",
    "    return issuance, retirement, projects       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e4bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issuance, df_retirement, df_projects = assign_methods(iss, ret, proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10ca1e",
   "metadata": {},
   "source": [
    "# CBL Prices\n",
    "## SIP Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5426afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from \\\"SIP_Settles\\\"'\n",
    "df_cbl_settles = pd.read_sql(query, engine)\n",
    "df_cbl_settles = df_cbl_settles[['Instrument','Date','Price']]\n",
    "df_cbl_settles['Date'] = pd.to_datetime(df_cbl_settles.Date).dt.date\n",
    "\n",
    "df_cbl_settles = df_cbl_settles[df_cbl_settles.Instrument.str.contains('CGEO1|CGEO2')==False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76739eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cbl_settles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ad2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spreads = df_cbl_settles.pivot_table('Price', 'Date', 'Instrument').reset_index()\n",
    "df_spreads['NGEO_GEO'] = df_spreads.NGEO - df_spreads.GEO\n",
    "df_spreads['NGEO_CGEO'] = df_spreads.NGEO - df_spreads.CGEO\n",
    "df_spreads['NGEO_SDGEO'] = df_spreads.NGEO - df_spreads.SDGEO\n",
    "df_spreads['SDGEO_GEO'] = df_spreads.SDGEO - df_spreads.GEO\n",
    "df_spreads['GEO_CGEO'] = df_spreads.GEO - df_spreads.CGEO\n",
    "df_spreads['CGEO_CGEOTR'] = df_spreads.CGEO - df_spreads['CGEO-TR']\n",
    "\n",
    "df_spreads = df_spreads[['Date','NGEO_GEO','NGEO_CGEO','NGEO_SDGEO','SDGEO_GEO','GEO_CGEO','CGEO_CGEOTR']]\n",
    "df_spreads = df_spreads.dropna(how='all',subset=list(df_spreads)[1:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0532e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from \\\"SIP_Trades\\\"'\n",
    "df_cbl_trades = pd.read_sql(query, engine)\n",
    "df_cbl_trades['Date'] = pd.to_datetime(df_cbl_trades['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trading data from yesterday to add to settles df\n",
    "max_date = max(df_cbl_trades.Date)\n",
    "daily_trades = df_cbl_trades[df_cbl_trades.Date==max_date]\n",
    "\n",
    "daily_high = []\n",
    "daily_low = []\n",
    "daily_volume = []\n",
    "product=[]\n",
    "date=[]\n",
    "for p in list(daily_trades.Instrument.unique()):\n",
    "    date.append(max_date)\n",
    "    product.append(p)\n",
    "    sub_df = daily_trades[daily_trades.Instrument==p]\n",
    "    daily_high.append(sub_df.Price.max())\n",
    "    daily_low.append(sub_df.Price.min())\n",
    "    daily_volume.append(sum(sub_df.Quantity))\n",
    "    \n",
    "daily_settles = pd.DataFrame()\n",
    "daily_settles['Date'] = date\n",
    "daily_settles['Product'] = product   \n",
    "daily_settles['High'] = daily_high\n",
    "daily_settles['Low'] = daily_low\n",
    "daily_settles['Volume'] = daily_volume\n",
    "\n",
    "print(daily_settles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc9a3ff",
   "metadata": {},
   "source": [
    "## Historical Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755915ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "candlestick_frames = {}\n",
    "# Create OHLC charts for the products\n",
    "for p in list(df_cbl_settles.Instrument.unique()):\n",
    "    sub_df = df_cbl_trades[df_cbl_trades.Instrument==p].reset_index(drop=True)\n",
    "    date_list = list(sub_df.Date.unique())\n",
    "    #open_list = []\n",
    "    high_list = []\n",
    "    low_list = []\n",
    "    #close_list = []\n",
    "    volume_list = []\n",
    "    for i,d in enumerate(date_list):\n",
    "        subsub_df = sub_df[sub_df.Date==d]\n",
    "        high_list.append(subsub_df.Price.max())\n",
    "        low_list.append(subsub_df.Price.min())\n",
    "        volume_list.append(sum(subsub_df.Quantity))\n",
    "    # Construct the frames\n",
    "    candlestick_frames[p] = pd.DataFrame()\n",
    "    candlestick_frames[p]['Date'] = date_list\n",
    "    candlestick_frames[p]['High'] = high_list\n",
    "    candlestick_frames[p]['Low'] = low_list\n",
    "    candlestick_frames[p]['Volume'] = volume_list\n",
    "    candlestick_frames[p] = candlestick_frames[p].sort_values(by='Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cef005",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod in list(df_cbl_settles.Instrument.unique()):\n",
    "    if prod == 'CGEO1':\n",
    "        pass\n",
    "    if prod == 'CGEO2':\n",
    "        pass\n",
    "    sub_df = candlestick_frames[prod]\n",
    "    #fig = go.Figure()\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "    fig.add_scatter(x=sub_df.Date, y=sub_df.High, mode='lines+markers', name='High', row=1, col=1)\n",
    "    fig.add_scatter(x=sub_df.Date, y=sub_df.Low, mode='lines+markers', name='Low', row=1, col=1)\n",
    "    fig.add_trace(go.Bar(x=sub_df.Date, y=sub_df.Volume, name='Volume'),row=2, col=1)\n",
    "    fig.update_layout(title='{} Daily High and Low'.format(prod))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd434f93",
   "metadata": {},
   "source": [
    "## SIP Historical Spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537dccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in list(df_spreads)[1:]:\n",
    "    fig.add_scatter(x=df_spreads.Date, y=df_spreads[i], mode='lines+markers', name=i)\n",
    "fig.update_layout(title='Spot CBL SIP Spreads')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca849be",
   "metadata": {},
   "source": [
    "# Our Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49291dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from \\\"VCS_Holdings\\\"'\n",
    "vcs_holdings = pd.read_sql(query, engine)\n",
    "our_projects = list(vcs_holdings['Project ID'].unique())\n",
    "\n",
    "query = 'select * from \\\"Broker_Markets\\\"'\n",
    "broker_markets = pd.read_sql(query, engine)\n",
    "\n",
    "df_matches = broker_markets[broker_markets['Project ID'].isin(our_projects)]\n",
    "vcs_holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574aea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'https://gist.githubusercontent.com/chriddyp/cb5392c35661370d95f300086accea51/raw/8e0768211f6b747c0db42a9ce9a0937dafcbd8b2/indicators.csv'\n",
    "\n",
    "EXPLANATION = \"\"\"\\\n",
    "<div class=\"app-sidebar\">\n",
    "<p><em>Compare different development indicators.</em><p>\n",
    "\n",
    "<p>Select what indicators to plot in the dropdowns, and use the slider\n",
    "to sub-select a fraction of years to include in the plot.</p>\n",
    "\n",
    "<p>Data and idea copied from the <a href=\"https://dash.plot.ly/getting-started-part-2\">\n",
    "Plotly Dash documentation</a>.</p>\n",
    "\n",
    "<p>This example demonstrates combining matplotlib with Jupyter widgets. For more interactive plots,\n",
    "consider using <a href=\"https://github.com/bloomberg/bqplot\">bqplot</a>.\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcace7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\\\n",
    "<style>\n",
    ".app-subtitle {\n",
    "    font-size: 1.5em;\n",
    "}\n",
    "\n",
    ".app-subtitle a {\n",
    "    color: #106ba3;\n",
    "}\n",
    "\n",
    ".app-subtitle a:hover {\n",
    "    text-decoration: underline;\n",
    "}\n",
    "\n",
    ".app-sidebar p {\n",
    "    margin-bottom: 1em;\n",
    "    line-height: 1.7;\n",
    "}\n",
    "\n",
    ".app-sidebar a {\n",
    "    color: #106ba3;\n",
    "}\n",
    "\n",
    ".app-sidebar a:hover {\n",
    "    text-decoration: underline;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a22406",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filtering:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        projects = list(self.df['Project ID'].unique())\n",
    "        projects.sort()\n",
    "        projects.insert(0,'All')\n",
    "        vins = list(self.df.Vintage.unique())\n",
    "        vins.sort()\n",
    "        vins.insert(0,'All')\n",
    "        offer_types = ['All','Bid','Offer','Trade']\n",
    "        \n",
    "        self.project_dropdown = self._generate_dropdown(projects, 0)\n",
    "        self.vin_dropdown = self._generate_dropdown(vins, 0)\n",
    "        self.type_dropdown = self._generate_dropdown(offer_types, 0)\n",
    "        self._plot_container = widgets.Output(layout=widgets.Layout(flex='0 1 auto'))\n",
    "        \n",
    "        _app_container = widgets.VBox([\n",
    "            widgets.HBox([self.project_dropdown, self.vin_dropdown, self.type_dropdown]),\n",
    "            self._plot_container\n",
    "        ], layout=widgets.Layout(align_items='flex-start', flex='3 0 auto'))        \n",
    "        \n",
    "        self.container = widgets.VBox([\n",
    "            widgets.HTML(\n",
    "                (\n",
    "                    '<h1>Broker Markets on Our Projects</h1>'\n",
    "                    '<h2 class=\"app-subtitle\"><a href=\"https://github.com/pbugnion/voila-gallery/blob/master/country-indicators/index.ipynb\">Link to code</a></h2>'\n",
    "                ), \n",
    "                layout=widgets.Layout(align_items='flex-start')#margin='0 0 5em 0')\n",
    "            ),\n",
    "            widgets.HBox([\n",
    "                _app_container, \n",
    "                #widgets.HTML(EXPLANATION, layout=widgets.Layout(align_items='flex-start'))#margin='0 0 0 2em'))\n",
    "                widgets.HTML(layout=widgets.Layout(align_items='flex-start'))#margin='0 0 0 2em'))\n",
    "            ])\n",
    "        ])#, layout=widgets.Layout(align_items='flex-start'))#,flex='1 1 auto', margin='0 auto 0 auto', max_width='1024px'))\n",
    "        self.update_app()        \n",
    "        \n",
    "    #def _generate_dropdown(self, content, name):\n",
    "    def _generate_dropdown(self, content, initial_index):        \n",
    "        #dropdown = widgets.SelectMultiple(options=content, value=[content[0]], description=name, disabled=False)\n",
    "        dropdown = widgets.Dropdown(options=content, value=content[initial_index])\n",
    "        dropdown.observe(self.on_change, names=['value'])\n",
    "        return dropdown\n",
    "    \n",
    "    def generate_frame(self,proj,vin,offer):\n",
    "        if vin=='All':\n",
    "            if offer=='All':\n",
    "                sub_df = self.df[self.df['Project ID']==proj]\n",
    "                if proj=='All':\n",
    "                    sub_df = self.df.copy()\n",
    "            elif proj=='All':\n",
    "                sub_df = self.df[self.df['Price Type']==offer]\n",
    "            else:\n",
    "                sub_df = self.df[(self.df['Project ID']==proj) & (self.df['Price Type']==offer)]\n",
    "        elif offer=='All':\n",
    "            if proj=='All':\n",
    "                sub_df = self.df[self.df['Vintage']==vin]\n",
    "            else:\n",
    "                sub_df = self.df[(self.df['Project ID']==proj) & (self.df['Vintage']==vin)]\n",
    "        elif proj=='All':\n",
    "            if vin=='All':\n",
    "                sub_df = self.df[self.df['Price Type']==offer]\n",
    "            else:\n",
    "                sub_df = self.df[(self.df['Price Type']==offer) & (self.df['Vintage']==vin)]\n",
    "        else:\n",
    "            sub_df = self.df[(self.df['Project ID']==proj) & (self.df['Vintage']==vin) & (self.df['Price Type']==offer)]\n",
    "        sub_df['Date'] = pd.to_datetime(sub_df['Offer Date']).dt.date\n",
    "        \n",
    "        sub_df = sub_df[['Date', 'Project ID','Standard','Type','Name','Price Type','Vintage','Price','Volume','Broker']]\n",
    "        sub_df = sub_df.sort_values(by='Date', ascending=False)\n",
    "        \n",
    "        frame_values = []\n",
    "        for i in list(sub_df):\n",
    "            frame_values.append(sub_df[i].values.tolist())\n",
    "\n",
    "            fig = go.Figure(data=[go.Table(\n",
    "                header=dict(values=list(sub_df.columns),\n",
    "                            fill_color='paleturquoise',\n",
    "                            align='left'),\n",
    "                #cells=dict(values=frame_values,\n",
    "                #           fill_color='lavender',\n",
    "                #           align='left')\n",
    "                cells=dict(\n",
    "                        values=[sub_df[k].tolist() for k in sub_df.columns])\n",
    "                )], layout=go.Layout(height=600, width=1000))      \n",
    "        return fig\n",
    "    \n",
    "    def on_change(self, _):\n",
    "        self.update_app()\n",
    "        \n",
    "    def update_app(self):\n",
    "        project = self.project_dropdown.value\n",
    "        vintage = self.vin_dropdown.value\n",
    "        off_type = self.type_dropdown.value\n",
    "        self._plot_container.clear_output(wait=True)\n",
    "        with self._plot_container:\n",
    "            fig = self.generate_frame(project, vintage, off_type)\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Filtering(df_matches)\n",
    "\n",
    "app.container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63009e66",
   "metadata": {},
   "source": [
    "# Market Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da56e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngeo_balance = py_functions.unit_balance(merge_group='NGEO')\n",
    "df_ngeo_balance.columns = ['Issued','Retired','Balance']\n",
    "df_ngeo_balance = df_ngeo_balance.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f04d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly setup\n",
    "fig = go.Figure()\n",
    "\n",
    "# add trace for eat\n",
    "for col in list(df_ngeo_balance)[1:]:\n",
    "    #print(col)\n",
    "    fig.add_trace(go.Bar(x=df_ngeo_balance.Vintage, y=df_ngeo_balance[col], name = col))\n",
    "\n",
    "fig.update_layout(title=dict(text='NGEO Balance by Vintage'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b9ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
