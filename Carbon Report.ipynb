{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c6eabb",
   "metadata": {},
   "source": [
    "# Voluntary Carbon Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014be3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML\n",
    "\n",
    "plt.ioff();\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://Attunga01:875mSzNM@attunga-instance-1.c6crotlobtrk.us-east-2.rds.amazonaws.com/postgres')\n",
    "\n",
    "sip_products = ['GEO','NGEO','CGEO-TR','CGEO','GEO']\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a93de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retrieve_Data:\n",
    "    def __init__(self):\n",
    "        self.engine = create_engine('postgresql://Attunga01:875mSzNM@attunga-instance-1.c6crotlobtrk.us-east-2.rds.amazonaws.com/postgres')\n",
    "\n",
    "        query = 'select * from \\\"Verra_Issuance\\\"'\n",
    "        self.df_issuance = pd.read_sql(query, self.engine)\n",
    "        self.df_issuance = self.df_issuance.drop_duplicates()\n",
    "        self.df_issuance['From Vintage'] = pd.to_datetime(self.df_issuance['From Vintage'], format='%d/%m/%Y').dt.date\n",
    "        self.df_issuance['To Vintage'] = pd.to_datetime(self.df_issuance['To Vintage'], format='%d/%m/%Y').dt.date      \n",
    "        self.df_issuance['Vintage'] = [i.year for i in self.df_issuance['To Vintage']]  \n",
    "        \n",
    "        query = 'select * from \\\"Verra_Retirement\\\"'\n",
    "        self.df_retirement = pd.read_sql(query, self.engine)\n",
    "        self.df_retirement = self.df_retirement.drop_duplicates()\n",
    "        self.df_retirement['Date of Retirement'] = pd.to_datetime(self.df_retirement['Date of Retirement'], format='%Y-%m-%d').dt.date\n",
    "        self.df_retirement['From Vintage'] = pd.to_datetime(self.df_retirement['From Vintage'], format='%Y-%m-%d').dt.date\n",
    "        self.df_retirement['To Vintage'] = pd.to_datetime(self.df_retirement['To Vintage'], format='%Y-%m-%d').dt.date      \n",
    "        self.df_retirement['Vintage'] = [i.year for i in self.df_retirement['To Vintage']] \n",
    "\n",
    "        query = 'select * from \\\"VCS_Projects\\\"'\n",
    "        self.df_projects = pd.read_sql(query, self.engine)\n",
    "        self.df_projects = self.df_projects.drop_duplicates()\n",
    "        self.df_projects['Crediting Period Start Date'] = pd.to_datetime(self.df_projects['Crediting Period Start Date'], format='%Y-%m-%d').dt.date\n",
    "        self.df_projects['Crediting Period End Date'] = pd.to_datetime(self.df_projects['Crediting Period End Date'], format='%Y-%m-%d').dt.date\n",
    "\n",
    "        self.ngeo_issuance, self.ngeo_retirement = self.ngeo_eligibility()\n",
    "        \n",
    "    def ngeo_eligibility(self):\n",
    "        #---------------------\n",
    "        # One Hot Encode the certifications\n",
    "        certification_frame = (self.df_projects['Additional Issuance Certifications'].str.split(r's*,s*', expand=True)\n",
    "           .apply(pd.Series.value_counts, 1)\n",
    "           .iloc[:, 1:]\n",
    "           .fillna(0, downcast='infer'))\n",
    "        \n",
    "        # Add grouping columns (e.g. all SDG and all CCD)\n",
    "        sdg_cols = [col for col in certification_frame.columns if ':' in col]\n",
    "        ccb_cols = [col for col in certification_frame.columns if 'CCB-' in col]\n",
    "        \n",
    "        certification_frame['SDG'] = np.where((certification_frame[sdg_cols]==1).any(axis=1),1,0)\n",
    "        certification_frame['CCB'] = np.where((certification_frame[ccb_cols]==1).any(axis=1),1,0)\n",
    "        \n",
    "        try:\n",
    "            any_cert_cols = ['SDG','CCB','CORSIA','Social Carbon']\n",
    "            certification_frame['No Additional Cert'] = np.where((certification_frame[any_cert_cols]==0).all(axis=1),1,0)\n",
    "        except KeyError:\n",
    "            any_cert_cols = ['SDG','CCB']#,'Social Carbon']\n",
    "            certification_frame['No Additional Cert'] = np.where((certification_frame[any_cert_cols]==0).all(axis=1),1,0)\n",
    "        \n",
    "        self.df_projects = pd.concat([self.df_projects, certification_frame], axis=1)\n",
    "        self.df_projects = self.df_projects.drop(columns=['Additional Issuance Certifications'])\n",
    "        #------------------------\n",
    "        #------------------------\n",
    "        # Determine NGEO Eligible Projects\n",
    "        ngeo_projects = self.df_projects[(self.df_projects.CCB==1)]\n",
    "        ngeo_projects = ngeo_projects.drop_duplicates(subset='Project ID')\n",
    "        \n",
    "        ngeo_projects = list(ngeo_projects['Project ID'].unique())\n",
    "        #--------------------------\n",
    "        #--------------------------\n",
    "        # Get supply / demand of NGEO eligible projects\n",
    "        ngeo_issuance = self.df_issuance[self.df_issuance['Project ID'].isin(ngeo_projects)].drop_duplicates()\n",
    "        ngeo_retirement = self.df_retirement[self.df_retirement['Project ID'].isin(ngeo_projects)].drop_duplicates()\n",
    "        return ngeo_issuance, ngeo_retirement   \n",
    "\n",
    "    def assign_methods(self):\n",
    "        # COOKSTOVES #\n",
    "        cookstrings = ['Stove','stove','Cooking','cooking','Cook','cook', 'STOVE','COOK', 'stew']\n",
    "        df_stove = self.df_issuance[self.df_issuance['Project Name'].str.contains('Stove')]\n",
    "        for c in cookstrings[1:]:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(c)]\n",
    "            df_stove = pd.concat([df_stove, df_sub])\n",
    "        df_stove = df_stove.drop_duplicates()\n",
    "        df_stove['Method'] = 'cookstoves'\n",
    "        \n",
    "        # SOLAR #\n",
    "        solarstrings = ['Solar','solar','Photo','photo','PV', 'SOLAR', 'Pv']\n",
    "        df_solar = self.df_issuance[self.df_issuance['Project Name'].str.contains('Solar')]\n",
    "        for s in solarstrings[1:]:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(s)]\n",
    "            df_solar = pd.concat([df_solar, df_sub])\n",
    "        df_solar = df_solar.drop_duplicates()\n",
    "        df_solar['Method'] = 'solar'\n",
    "        \n",
    "        # HYDRO #\n",
    "        strings = ['Hydro','hydro','River','river','HEPP', 'HYDRO', 'Foz do', 'Pizarras', 'Fundao', 'Hyrdro', 'Low Dam']\n",
    "        df_hydro = self.df_issuance[self.df_issuance['Project Name'].str.contains('Hydro')]\n",
    "        for s in strings[1:]:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(s)]\n",
    "            df_hydro = pd.concat([df_hydro, df_sub])\n",
    "        df_hydro = df_hydro.drop_duplicates()\n",
    "        df_hydro['Method'] = 'hydro'\n",
    "        \n",
    "        # WIND #\n",
    "        strings = ['Wind','wind', 'WIND']\n",
    "        df_wind = self.df_issuance[self.df_issuance['Project Name'].str.contains('Wind')]\n",
    "        for s in strings[1:]:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(s)]\n",
    "            df_wind = pd.concat([df_wind, df_sub])\n",
    "        df_wind = df_wind.drop_duplicates()\n",
    "        df_wind['Method'] = 'wind'\n",
    "        \n",
    "        # LANDFILL GAS / WASTE / Fugitive Emissions / CCS #\n",
    "        strings = ['Fill','fill', 'Waste','waste','CMM','CCS','capture','Capture', 'Biogas','biogas', 'LFG', 'Methane','methane','METHANE','Gas','gas', 'Biomass','biomass', 'compost', 'LNG', 'LANDFILL', 'Compost', 'Composting']\n",
    "        df_lfg = self.df_issuance[self.df_issuance['Project Type'].str.contains('Fugitive')]\n",
    "        for s in strings:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(s)]\n",
    "            df_lfg = pd.concat([df_lfg, df_sub])\n",
    "        df_lfg = df_lfg[~df_lfg['Project Type'].str.contains('Livestock')]\n",
    "        df_lfg = df_lfg[~df_lfg['Project Type'].str.contains('Forest')]\n",
    "        df_lfg = df_lfg.drop_duplicates()\n",
    "        df_lfg['Method'] = 'lfg_ccs_gas_biomass'\n",
    "        \n",
    "        # GEOTHERMAL / BIOMASS #\n",
    "        strings = ['Geothermal','geothermal', 'Thermal','thermal']\n",
    "        df_geothermal = self.df_issuance[self.df_issuance['Project Name'].str.contains('Geothermal')]\n",
    "        for s in strings[1:]:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(s)]\n",
    "            df_geothermal = pd.concat([df_geothermal, df_sub])\n",
    "        df_geothermal = df_geothermal.drop_duplicates()\n",
    "        df_geothermal['Method'] = 'geothermal'\n",
    "        \n",
    "        # LIVESTOCK / METHANE #\n",
    "        strings = ['Methane','methane','Dairy','dairy']\n",
    "        df_livestock = self.df_issuance[self.df_issuance['Project Name'].str.contains('Methane')]\n",
    "        for s in strings[1:]:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(s)]\n",
    "            df_livestock = pd.concat([df_livestock, df_sub])\n",
    "        df_livestock = df_livestock[df_livestock['Project Type'].str.contains('Livestock')]    \n",
    "        df_livestock = df_livestock.drop_duplicates()\n",
    "        df_livestock['Method'] = 'livestock_methane'\n",
    "        \n",
    "        # FUEL SWITCHING #\n",
    "        strings = ['Switching','SWITCHING','switching', 'Husk', 'husk', 'Smelter', 'smelter', 'Switch']\n",
    "        df_switching = self.df_issuance[self.df_issuance['Project Name'].str.contains('Switching')]\n",
    "        for s in strings[1:]:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(s)]\n",
    "            df_switching = pd.concat([df_switching, df_sub])  \n",
    "        df_switching = df_switching.drop_duplicates()\n",
    "        df_switching['Method'] = 'fuel_switching'\n",
    "        \n",
    "        ## AFFORESTATION ##\n",
    "        strings = ['Afforestation','afforestation','Plantation','plantation']\n",
    "        arr_projects = self.df_projects[self.df_projects['AFOLU Activities']=='ARR']\n",
    "        arr_projects = list(arr_projects['Project ID'].unique())\n",
    "        \n",
    "        df_arr = self.df_issuance[self.df_issuance['Project Name'].str.contains('Afforestation')]\n",
    "        for s in strings[1:]:\n",
    "            df_sub = self.df_issuance[self.df_issuance['Project Name'].str.contains(s)]\n",
    "            df_arr = pd.concat([df_arr, df_sub])\n",
    "        x = self.df_issuance[self.df_issuance['Project ID'].isin(arr_projects)]\n",
    "        df_arr = pd.concat([df_arr, x])\n",
    "        df_arr = df_arr.drop_duplicates()\n",
    "        df_arr['Method'] = 'arr'\n",
    "        \n",
    "        ## AVOIDED DEFORESTATION ##\n",
    "        df_avoided = self.df_issuance[self.df_issuance['Project Type'].str.contains('Forest')]\n",
    "        affo_projects = list(df_arr['Project ID'].unique())\n",
    "        df_avoided = df_avoided[~df_avoided['Project ID'].isin(affo_projects)]\n",
    "        df_avoided['Method'] = 'forestry_avoided'\n",
    "        df_avoided = df_avoided.drop_duplicates()\n",
    "        \n",
    "        # Chemical #\n",
    "        df_chemical = self.df_issuance[self.df_issuance['Project Type'].str.contains('Chemical')]\n",
    "        df_chemical['Method'] = 'chemicals'\n",
    "        df_chemical = df_chemical.drop_duplicates()\n",
    "        \n",
    "        # Plastic #\n",
    "        df_plastic = self.df_issuance[self.df_issuance['Project Type'].str.contains('Plastic')]\n",
    "        df_plastic['Method'] = 'plastics'\n",
    "        df_plastic = df_plastic.drop_duplicates()\n",
    "        \n",
    "        # Transport #\n",
    "        df_transport = self.df_issuance[self.df_issuance['Project Type'].str.contains('Transport')]\n",
    "        df_transport['Method'] = 'transport'\n",
    "        df_transport = df_transport.drop_duplicates()\n",
    "        \n",
    "        # BLUE CARBON #\n",
    "        sub1 = self.df_issuance[self.df_issuance['Project Name'].str.contains('BLUE')]\n",
    "        sub2 = self.df_issuance[self.df_issuance['Project Name'].str.contains('Blue')]\n",
    "        df_blue = pd.concat([sub1, sub2])\n",
    "        df_blue['Method'] = 'Blue Carbon'\n",
    "        df_blue = df_blue.drop_duplicates()\n",
    "        \n",
    "        \n",
    "        ## MERGE THEM ALL TOGETHER ##\n",
    "        df_issuance_merged = pd.concat([df_blue, df_stove, df_solar, df_hydro, df_wind, df_lfg, df_livestock, df_arr, df_avoided, df_chemical, df_plastic, df_transport, df_geothermal, df_switching])\n",
    "        \n",
    "        # Other non-forestry # IDENTIFY THE MISSING PROJECTS\n",
    "        stripped_projects = list(df_issuance_merged['Project ID'].unique())\n",
    "        missing_projects = self.df_issuance[~self.df_issuance['Project ID'].isin(stripped_projects)] # find the projects that aren't yet accounted for\n",
    "        missing_projects['Method'] = 'other_non_forestry'\n",
    "        \n",
    "        df_issuance_merged = pd.concat([df_issuance_merged, missing_projects])\n",
    "        df_issuance_merged = df_issuance_merged.drop_duplicates(subset=list(df_issuance_merged)[:-1])\n",
    "        df_issuance_merged = df_issuance_merged.sort_values(by=['Issuance Date','Project ID','To Vintage'], ascending=[False, True, True])\n",
    "        self.df_issuance = df_issuance_merged.copy()\n",
    "        \n",
    "        ## UPDATE THE RETIREMENT DATA TO INCLUDE METHODS ##\n",
    "        sub_df = self.df_issuance[['Project ID','Method']]\n",
    "        df_retirement = self.df_retirement.merge(sub_df, on='Project ID')\n",
    "        df_retirement = df_retirement.drop_duplicates().reset_index(drop=True)\n",
    "        self.df_retirement = df_retirement.copy()\n",
    "        \n",
    "        ## UPDATE THE PROJECTS DATA TO INCLUDE METHODS ##\n",
    "        sub_df = self.df_issuance[['Project ID','Method']]\n",
    "        df_project = self.df_projects.merge(sub_df, on='Project ID')\n",
    "        df_project = df_project.drop_duplicates().reset_index(drop=True)\n",
    "        self.df_projects = df_project.copy()\n",
    "        \n",
    "    ##############################################################\n",
    "    # DATA MODELLING / ANALYSIS\n",
    "    ##############################################################\n",
    "    def unit_balance(self, merge_group='All'):\n",
    "        if merge_group=='All':\n",
    "            grouped_issuance = self.df_issuance.copy()\n",
    "            grouped_retirement = self.df_retirement.copy()\n",
    "            grouped_issuance = grouped_issuance.groupby(by='Vintage').sum()['Quantity of Units Issued'].reset_index()\n",
    "            grouped_retirement = grouped_retirement.groupby(by='Vintage').sum()['Quantity of Units'].reset_index()\n",
    "        elif merge_group=='NGEO':\n",
    "            grouped_issuance = self.ngeo_issuance.groupby(by='Vintage').sum()['Quantity of Units Issued'].reset_index()\n",
    "            grouped_retirement = self.ngeo_retirement.groupby(by='Vintage').sum()['Quantity of Units'].reset_index()\n",
    "        else:\n",
    "            grouped_issuance=self.df_issuance[self.df_issuance['Method']==merge_group].reset_index(drop=True)\n",
    "            grouped_retirement = self.df_retirement[self.df_retirement['Method']==merge_group].reset_index(drop=True)\n",
    "            grouped_issuance = grouped_issuance.groupby(by='Vintage').sum()['Quantity of Units Issued'].reset_index()\n",
    "            grouped_retirement = grouped_retirement.groupby(by='Vintage').sum()['Quantity of Units'].reset_index()\n",
    "        \n",
    "        method_balance = grouped_issuance.merge(grouped_retirement, how='left',on='Vintage')\n",
    "        method_balance['Remaining'] = method_balance['Quantity of Units Issued'] - method_balance['Quantity of Units']\n",
    "        \n",
    "        method_balance = method_balance.set_index('Vintage')\n",
    "        return method_balance    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_functions = Retrieve_Data()\n",
    "py_functions.assign_methods()  # label the issuance and retirement data based on methodologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c238526",
   "metadata": {},
   "source": [
    "# CBL Prices\n",
    "## SIP Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from \\\"SIP_Settles\\\"'\n",
    "df_cbl_settles = pd.read_sql(query, engine)\n",
    "df_cbl_settles = df_cbl_settles[['Instrument','Date','Price']]\n",
    "df_cbl_settles['Date'] = pd.to_datetime(df_cbl_settles.Date).dt.date\n",
    "\n",
    "df_cbl_settles = df_cbl_settles[df_cbl_settles.Instrument.str.contains('CGEO1|CGEO2')==False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4129a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spreads = df_cbl_settles.pivot_table('Price', 'Date', 'Instrument').reset_index()\n",
    "df_spreads['NGEO_GEO'] = df_spreads.NGEO - df_spreads.GEO\n",
    "df_spreads['NGEO_CGEO'] = df_spreads.NGEO - df_spreads.CGEO\n",
    "df_spreads['NGEO_SDGEO'] = df_spreads.NGEO - df_spreads.SDGEO\n",
    "df_spreads['SDGEO_GEO'] = df_spreads.SDGEO - df_spreads.GEO\n",
    "df_spreads['GEO_CGEO'] = df_spreads.GEO - df_spreads.CGEO\n",
    "df_spreads['CGEO_CGEOTR'] = df_spreads.CGEO - df_spreads['CGEO-TR']\n",
    "\n",
    "df_spreads = df_spreads[['Date','NGEO_GEO','NGEO_CGEO','NGEO_SDGEO','SDGEO_GEO','GEO_CGEO','CGEO_CGEOTR']]\n",
    "df_spreads = df_spreads.dropna(how='all',subset=list(df_spreads)[1:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc1fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from \\\"SIP_Trades\\\"'\n",
    "df_cbl_trades = pd.read_sql(query, engine)\n",
    "df_cbl_trades['Date'] = pd.to_datetime(df_cbl_trades['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc737a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trading data from yesterday to add to settles df\n",
    "max_date = max(df_cbl_trades.Date)\n",
    "daily_trades = df_cbl_trades[df_cbl_trades.Date==max_date]\n",
    "\n",
    "daily_high = []\n",
    "daily_low = []\n",
    "daily_volume = []\n",
    "product=[]\n",
    "date=[]\n",
    "for p in list(daily_trades.Instrument.unique()):\n",
    "    date.append(max_date)\n",
    "    product.append(p)\n",
    "    sub_df = daily_trades[daily_trades.Instrument==p]\n",
    "    daily_high.append(sub_df.Price.max())\n",
    "    daily_low.append(sub_df.Price.min())\n",
    "    daily_volume.append(sum(sub_df.Quantity))\n",
    "    \n",
    "daily_settles = pd.DataFrame()\n",
    "daily_settles['Date'] = date\n",
    "daily_settles['Product'] = product   \n",
    "daily_settles['High'] = daily_high\n",
    "daily_settles['Low'] = daily_low\n",
    "daily_settles['Volume'] = daily_volume\n",
    "\n",
    "print(daily_settles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3c4c3",
   "metadata": {},
   "source": [
    "## Historical Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd16e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "candlestick_frames = {}\n",
    "# Create OHLC charts for the products\n",
    "for p in list(df_cbl_settles.Instrument.unique()):\n",
    "    sub_df = df_cbl_trades[df_cbl_trades.Instrument==p].reset_index(drop=True)\n",
    "    date_list = list(sub_df.Date.unique())\n",
    "    #open_list = []\n",
    "    high_list = []\n",
    "    low_list = []\n",
    "    #close_list = []\n",
    "    volume_list = []\n",
    "    for i,d in enumerate(date_list):\n",
    "        subsub_df = sub_df[sub_df.Date==d]\n",
    "        high_list.append(subsub_df.Price.max())\n",
    "        low_list.append(subsub_df.Price.min())\n",
    "        volume_list.append(sum(subsub_df.Quantity))\n",
    "    # Construct the frames\n",
    "    candlestick_frames[p] = pd.DataFrame()\n",
    "    candlestick_frames[p]['Date'] = date_list\n",
    "    candlestick_frames[p]['High'] = high_list\n",
    "    candlestick_frames[p]['Low'] = low_list\n",
    "    candlestick_frames[p]['Volume'] = volume_list\n",
    "    candlestick_frames[p] = candlestick_frames[p].sort_values(by='Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e049cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod in list(df_cbl_settles.Instrument.unique()):\n",
    "    if prod == 'CGEO1':\n",
    "        pass\n",
    "    if prod == 'CGEO2':\n",
    "        pass\n",
    "    sub_df = candlestick_frames[prod]\n",
    "    #fig = go.Figure()\n",
    "    fig = make_subplots(rows=2, cols=1)\n",
    "    fig.add_scatter(x=sub_df.Date, y=sub_df.High, mode='lines+markers', name='High', row=1, col=1)\n",
    "    fig.add_scatter(x=sub_df.Date, y=sub_df.Low, mode='lines+markers', name='Low', row=1, col=1)\n",
    "    fig.add_trace(go.Bar(x=sub_df.Date, y=sub_df.Volume, name='Volume'),row=2, col=1)\n",
    "    fig.update_layout(title='{} Daily High and Low'.format(prod))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f1335",
   "metadata": {},
   "source": [
    "## SIP Historical Spreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i in list(df_spreads)[1:]:\n",
    "    fig.add_scatter(x=df_spreads.Date, y=df_spreads[i], mode='lines+markers', name=i)\n",
    "fig.update_layout(title='Spot CBL SIP Spreads')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3786f307",
   "metadata": {},
   "source": [
    "# Our Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'select * from \\\"VCS_Holdings\\\"'\n",
    "vcs_holdings = pd.read_sql(query, engine)\n",
    "our_projects = list(vcs_holdings['Project ID'].unique())\n",
    "\n",
    "query = 'select * from \\\"Broker_Markets\\\"'\n",
    "broker_markets = pd.read_sql(query, engine)\n",
    "\n",
    "df_matches = broker_markets[broker_markets['Project ID'].isin(our_projects)]\n",
    "vcs_holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e76276",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = 'https://gist.githubusercontent.com/chriddyp/cb5392c35661370d95f300086accea51/raw/8e0768211f6b747c0db42a9ce9a0937dafcbd8b2/indicators.csv'\n",
    "\n",
    "EXPLANATION = \"\"\"\\\n",
    "<div class=\"app-sidebar\">\n",
    "<p><em>Compare different development indicators.</em><p>\n",
    "\n",
    "<p>Select what indicators to plot in the dropdowns, and use the slider\n",
    "to sub-select a fraction of years to include in the plot.</p>\n",
    "\n",
    "<p>Data and idea copied from the <a href=\"https://dash.plot.ly/getting-started-part-2\">\n",
    "Plotly Dash documentation</a>.</p>\n",
    "\n",
    "<p>This example demonstrates combining matplotlib with Jupyter widgets. For more interactive plots,\n",
    "consider using <a href=\"https://github.com/bloomberg/bqplot\">bqplot</a>.\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\\\n",
    "<style>\n",
    ".app-subtitle {\n",
    "    font-size: 1.5em;\n",
    "}\n",
    "\n",
    ".app-subtitle a {\n",
    "    color: #106ba3;\n",
    "}\n",
    "\n",
    ".app-subtitle a:hover {\n",
    "    text-decoration: underline;\n",
    "}\n",
    "\n",
    ".app-sidebar p {\n",
    "    margin-bottom: 1em;\n",
    "    line-height: 1.7;\n",
    "}\n",
    "\n",
    ".app-sidebar a {\n",
    "    color: #106ba3;\n",
    "}\n",
    "\n",
    ".app-sidebar a:hover {\n",
    "    text-decoration: underline;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a69040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filtering:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        projects = list(self.df['Project ID'].unique())\n",
    "        projects.sort()\n",
    "        projects.insert(0,'All')\n",
    "        vins = list(self.df.Vintage.unique())\n",
    "        vins.sort()\n",
    "        vins.insert(0,'All')\n",
    "        offer_types = ['All','Bid','Offer','Trade']\n",
    "        \n",
    "        self.project_dropdown = self._generate_dropdown(projects, 0)\n",
    "        self.vin_dropdown = self._generate_dropdown(vins, 0)\n",
    "        self.type_dropdown = self._generate_dropdown(offer_types, 0)\n",
    "        self._plot_container = widgets.Output(layout=widgets.Layout(flex='0 1 auto'))\n",
    "        \n",
    "        _app_container = widgets.VBox([\n",
    "            widgets.HBox([self.project_dropdown, self.vin_dropdown, self.type_dropdown]),\n",
    "            self._plot_container\n",
    "        ], layout=widgets.Layout(align_items='flex-start', flex='3 0 auto'))        \n",
    "        \n",
    "        self.container = widgets.VBox([\n",
    "            widgets.HTML(\n",
    "                (\n",
    "                    '<h1>Broker Markets on Our Projects</h1>'\n",
    "                    '<h2 class=\"app-subtitle\"><a href=\"https://github.com/pbugnion/voila-gallery/blob/master/country-indicators/index.ipynb\">Link to code</a></h2>'\n",
    "                ), \n",
    "                layout=widgets.Layout(align_items='flex-start')#margin='0 0 5em 0')\n",
    "            ),\n",
    "            widgets.HBox([\n",
    "                _app_container, \n",
    "                #widgets.HTML(EXPLANATION, layout=widgets.Layout(align_items='flex-start'))#margin='0 0 0 2em'))\n",
    "                widgets.HTML(layout=widgets.Layout(align_items='flex-start'))#margin='0 0 0 2em'))\n",
    "            ])\n",
    "        ])#, layout=widgets.Layout(align_items='flex-start'))#,flex='1 1 auto', margin='0 auto 0 auto', max_width='1024px'))\n",
    "        self.update_app()        \n",
    "        \n",
    "    #def _generate_dropdown(self, content, name):\n",
    "    def _generate_dropdown(self, content, initial_index):        \n",
    "        #dropdown = widgets.SelectMultiple(options=content, value=[content[0]], description=name, disabled=False)\n",
    "        dropdown = widgets.Dropdown(options=content, value=content[initial_index])\n",
    "        dropdown.observe(self.on_change, names=['value'])\n",
    "        return dropdown\n",
    "    \n",
    "    def generate_frame(self,proj,vin,offer):\n",
    "        if vin=='All':\n",
    "            if offer=='All':\n",
    "                sub_df = self.df[self.df['Project ID']==proj]\n",
    "                if proj=='All':\n",
    "                    sub_df = self.df.copy()\n",
    "            elif proj=='All':\n",
    "                sub_df = self.df[self.df['Price Type']==offer]\n",
    "            else:\n",
    "                sub_df = self.df[(self.df['Project ID']==proj) & (self.df['Price Type']==offer)]\n",
    "        elif offer=='All':\n",
    "            if proj=='All':\n",
    "                sub_df = self.df[self.df['Vintage']==vin]\n",
    "            else:\n",
    "                sub_df = self.df[(self.df['Project ID']==proj) & (self.df['Vintage']==vin)]\n",
    "        elif proj=='All':\n",
    "            if vin=='All':\n",
    "                sub_df = self.df[self.df['Price Type']==offer]\n",
    "            else:\n",
    "                sub_df = self.df[(self.df['Price Type']==offer) & (self.df['Vintage']==vin)]\n",
    "        else:\n",
    "            sub_df = self.df[(self.df['Project ID']==proj) & (self.df['Vintage']==vin) & (self.df['Price Type']==offer)]\n",
    "        sub_df['Date'] = pd.to_datetime(sub_df['Offer Date']).dt.date\n",
    "        \n",
    "        sub_df = sub_df[['Date', 'Project ID','Standard','Type','Name','Price Type','Vintage','Price','Volume','Broker']]\n",
    "        sub_df = sub_df.sort_values(by='Date', ascending=False)\n",
    "        \n",
    "        frame_values = []\n",
    "        for i in list(sub_df):\n",
    "            frame_values.append(sub_df[i].values.tolist())\n",
    "\n",
    "            fig = go.Figure(data=[go.Table(\n",
    "                header=dict(values=list(sub_df.columns),\n",
    "                            fill_color='paleturquoise',\n",
    "                            align='left'),\n",
    "                #cells=dict(values=frame_values,\n",
    "                #           fill_color='lavender',\n",
    "                #           align='left')\n",
    "                cells=dict(\n",
    "                        values=[sub_df[k].tolist() for k in sub_df.columns])\n",
    "                )], layout=go.Layout(height=600, width=1000))      \n",
    "        return fig\n",
    "    \n",
    "    def on_change(self, _):\n",
    "        self.update_app()\n",
    "        \n",
    "    def update_app(self):\n",
    "        project = self.project_dropdown.value\n",
    "        vintage = self.vin_dropdown.value\n",
    "        off_type = self.type_dropdown.value\n",
    "        self._plot_container.clear_output(wait=True)\n",
    "        with self._plot_container:\n",
    "            fig = self.generate_frame(project, vintage, off_type)\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Filtering(df_matches)\n",
    "\n",
    "app.container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aff644",
   "metadata": {},
   "source": [
    "# Market Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8013788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ngeo_balance = py_functions.unit_balance(merge_group='NGEO')\n",
    "df_ngeo_balance.columns = ['Issued','Retired','Balance']\n",
    "df_ngeo_balance = df_ngeo_balance.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd26913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly setup\n",
    "fig = go.Figure()\n",
    "\n",
    "# add trace for eat\n",
    "for col in list(df_ngeo_balance)[1:]:\n",
    "    #print(col)\n",
    "    fig.add_trace(go.Bar(x=df_ngeo_balance.Vintage, y=df_ngeo_balance[col], name = col))\n",
    "\n",
    "fig.update_layout(title=dict(text='NGEO Balance by Vintage'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaced4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
